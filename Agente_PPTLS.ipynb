{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **Imports**"],"metadata":{"id":"q1o2-sAMcjMi"}},{"cell_type":"code","source":["import enum\n","import typing\n","import urllib\n","import collections\n","import abc\n","import numpy as np"],"metadata":{"id":"3jdzFfRbcpfT","executionInfo":{"status":"ok","timestamp":1685375784528,"user_tz":-120,"elapsed":9,"user":{"displayName":"Nacho","userId":"01555914631003755754"}}},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":["# Definición de las diferentes acciones"],"metadata":{"id":"oP3bK-IccuUR"}},{"cell_type":"code","source":["class Action(enum.Enum):\n","    \"\"\"Cada una de las posibles figuras.\"\"\"\n","    ROCK = '🪨 Rock'\n","    PAPER = '🧻 Paper'\n","    SCISSORS = '✂️ Scissors'\n","    LIZARD = '🦎 Lizard'\n","    SPOCK = '🖖 Spock'"],"metadata":{"id":"bXpIGrbmc1QS","executionInfo":{"status":"ok","timestamp":1685375784528,"user_tz":-120,"elapsed":8,"user":{"displayName":"Nacho","userId":"01555914631003755754"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["# Definicion de las diferentes recompensas según cada acción"],"metadata":{"id":"cJX7wIrLdIKj"}},{"cell_type":"code","source":["MOVES_AND_REWARDS = {\n","    (Action.ROCK, Action.ROCK): 0, (Action.ROCK, Action.PAPER): -1,\n","    (Action.ROCK, Action.SCISSORS): 1, (Action.ROCK, Action.LIZARD): 1,\n","    (Action.ROCK, Action.SPOCK): -1,\n","    (Action.PAPER, Action.ROCK): 1, (Action.PAPER, Action.PAPER): 0,\n","    (Action.PAPER, Action.SCISSORS): -1, (Action.PAPER, Action.LIZARD): -1,\n","    (Action.PAPER, Action.SPOCK): 1,\n","    (Action.SCISSORS, Action.ROCK): -1, (Action.SCISSORS, Action.PAPER): 1,\n","    (Action.SCISSORS, Action.SCISSORS): 0, (Action.SCISSORS, Action.LIZARD): 1,\n","    (Action.SCISSORS, Action.SPOCK): -1,\n","    (Action.LIZARD, Action.ROCK): -1, (Action.LIZARD, Action.PAPER): 1,\n","    (Action.LIZARD, Action.SCISSORS): -1, (Action.LIZARD, Action.LIZARD): 0,\n","    (Action.LIZARD, Action.SPOCK): 1,\n","    (Action.SPOCK, Action.ROCK): 1, (Action.SPOCK, Action.PAPER): -1,\n","    (Action.SPOCK, Action.SCISSORS): 1, (Action.SPOCK, Action.LIZARD): -1,\n","    (Action.SPOCK, Action.SPOCK): 0,\n","}"],"metadata":{"id":"e1OBhV8EdOep","executionInfo":{"status":"ok","timestamp":1685375784529,"user_tz":-120,"elapsed":8,"user":{"displayName":"Nacho","userId":"01555914631003755754"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["# Creación del juego"],"metadata":{"id":"O8IgzsftdX5Z"}},{"cell_type":"code","source":["class Game:\n","    RENDER_MODE_HUMAN = 'human'\n","    \n","    def __init__(self, render_mode=None):\n","        self.render_mode = render_mode\n","\n","    def play(self, p1_action, p2_action):\n","        result = MOVES_AND_REWARDS[(p1_action, p2_action)]\n","        if self.render_mode == 'human':\n","            self.render(p1_action, p2_action, result)\n","        return result\n","    \n","    @staticmethod\n","    def render(p1_action, p2_action, result):\n","        if result == 0:\n","            print(f'{p1_action.value} tie!')\n","        elif result == 1:\n","            print(f'{p1_action.value} beats {p2_action.value}')\n","        elif result == -1:\n","            print(f'{p2_action.value} beats {p1_action.value}')\n","        else:\n","            raise ValueError(f'{p1_action}, {p2_action}, {result}')"],"metadata":{"id":"kTiX64vtdaYJ","executionInfo":{"status":"ok","timestamp":1685375784529,"user_tz":-120,"elapsed":8,"user":{"displayName":"Nacho","userId":"01555914631003755754"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["# Definición de la calse Transition"],"metadata":{"id":"qLliPXcMdnIT"}},{"cell_type":"code","source":["class Transition(typing.NamedTuple):\n","    \"\"\"Representa la transición de un estado al siguiente\"\"\"\n","    prev_state: int              # Estado origen de la transición\n","    next_state: int              # Estado destino de la transición\n","    action: Action               # Acción que provocó esta transición\n","    reward: typing.SupportsFloat # Recompensa obtenida"],"metadata":{"id":"2kuZTDQDdwpp","executionInfo":{"status":"ok","timestamp":1685375787504,"user_tz":-120,"elapsed":2,"user":{"displayName":"Nacho","userId":"01555914631003755754"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["# **Clase Agent abstracta**"],"metadata":{"id":"Ux0nS3P4cTmK"}},{"cell_type":"code","source":["class Agent(metaclass=abc.ABCMeta):\n","    \n","    @abc.abstractmethod\n","    def __init__(self, name: str):\n","        \"\"\"Inicializa el objeto.\n","        \n","        :param name: El nombre del agente.\n","        \"\"\"\n","        self.name = name\n","\n","    @abc.abstractmethod\n","    def decide(self, state:int) -> Action:\n","        \"\"\"Decide la acción a llevar a cabo dado el estado actual.\n","        \n","        :param state: El estado en el que se encuentra el agente.\n","        :returns: La acción a llevar a cabo.\n","        \"\"\"\n","    \n","    def update(self, transition: Transition):\n","        \"\"\"Actualiza (si es necesario) el estado interno del agente.\n","        \n","        :param transition: La información de la transición efectuada.\n","        \"\"\"\n","        pass\n","    \n","    def __str__(self):\n","        return self.name"],"metadata":{"id":"Q1ZsCYZ3cbGT","executionInfo":{"status":"ok","timestamp":1685375789943,"user_tz":-120,"elapsed":2,"user":{"displayName":"Nacho","userId":"01555914631003755754"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["# **Definicion de nuestro agente (TechNoir)**"],"metadata":{"id":"A5PyvSxceGMq"}},{"cell_type":"code","source":["class TechNoirAgent(Agent):\n","    def __init__(self, q_table: typing.Any=None):\n","        \"\"\"Inicializa este objeto.\n","        \n","        :param name: El nombre del agente, para identificarle.\n","        :param q_table: Una tabla q de valores. Es opcional.\n","        \"\"\"\n","\n","        super().__init__(name='TechNoir Agent')\n","        if q_table:\n","            q_table = q_table\n","        else:\n","            self.q_table = {}\n","\n","    def decide(self, state:int, 𝜀: typing.SupportsFloat=0) -> Action:\n","        \"\"\"Decide la acción a ejecutar.\n","        \n","        :param state: El estado en el que nos encontramos.\n","        :param 𝜀: Un valor entre 0 y 1 que representa, según la estrategia\n","            ε-greedy, la probabilidad de que la acción sea elegida de manera\n","            aleatoria de entre todas las opciones posibles. Es opcional, y si\n","            no se especifica su valor es 0 (sin probabilidades de que se elija\n","            una acción aleatoria).\n","        :param returns: La acción a ejecutar.\n","        \"\"\"\n","        \n","        if np.random.random() < 𝜀:\n","            action = np.random.choice(list(Action))\n","        else:\n","            q_values = self.q_table.get(state, {action: 0 for action in Action})\n","            action = max(q_values, key=q_values.get)\n","        \n","        return action\n","\n","    def update(self, t: Transition, 𝛼=0.01, 𝛾=0.95):\n","        \"\"\"Actualiza el estado interno de acuerdo a la experiencia vivida.\n","        \n","        :param transition: Toda la información correspondiente a la transición\n","            de la que queremos aprender.\n","        :param 𝛼: El factor de aprendizaje del cambio en el valor q. Por\n","            defecto es 0.1\n","        :param 𝛾: La influencia de la recompensa a largo plazo en el valor q a\n","            actualizar. Va de 0 (sin influencia) a 1 (misma influencia que el\n","            valor actual). Por defecto es 0.95.\n","        \"\"\"\n","        prev_q_values = self.q_table.get(t.prev_state, {action: 0 for action in Action})\n","        next_q_values = self.q_table.get(t.next_state, {action: 0 for action in Action})\n","        \n","        max_q_value = max(next_q_values.values())\n","        \n","        prev_q_values[t.action] = (1 - 𝛼) * prev_q_values[t.action] + 𝛼 * (t.reward + 𝛾 * max_q_value)\n","        \n","        self.q_table[t.prev_state] = prev_q_values\n","\n","    def __strQTable__(self) -> str:\n","        \"\"\"Representación textual de la tabla Q del agente.\n","        \n","        :returns: Una cadena indicando la estructura interna de la tabla Q.\n","        \"\"\"\n","\n","        q_table_str = \"\"\n","        for state, q_values in self.q_table.items():\n","            q_table_str += f\"State {state}: {q_values}\\n\"\n","        \n","        return q_table_str"],"metadata":{"id":"zYwZXXxSeJ2h","executionInfo":{"status":"ok","timestamp":1685376461453,"user_tz":-120,"elapsed":2,"user":{"displayName":"Nacho","userId":"01555914631003755754"}}},"execution_count":80,"outputs":[]},{"cell_type":"markdown","source":["# Carga del dataset para entrenamiento"],"metadata":{"id":"XFbDuktae7II"}},{"cell_type":"code","source":["dataset_url = 'https://blazaid.github.io/Aprendizaje-profundo/Datasets/rock-paper-scissors-lizard-spock.trn'\n","\n","player2_actions = []\n","with urllib.request.urlopen(dataset_url) as f:\n","    for line in f:\n","        move = line.decode('utf-8').strip().upper()\n","        if move:\n","            player2_actions.append(Action[move])"],"metadata":{"id":"9gwkj2pHfBEw","executionInfo":{"status":"ok","timestamp":1685376462745,"user_tz":-120,"elapsed":218,"user":{"displayName":"Nacho","userId":"01555914631003755754"}}},"execution_count":81,"outputs":[]},{"cell_type":"markdown","source":["# Entrenamiento del agente"],"metadata":{"id":"vDw8gXTCfI9y"}},{"cell_type":"code","source":["𝜀 = 1\n","𝛿𝜀 = 𝜀 / len(player2_actions)\n","\n","game = Game()\n","agent = TechNoirAgent()\n","\n","state = 0  # El entorno (juego) no tiene estado, así que siempre será el mismo\n","for p2_action in player2_actions:\n","    p1_action = agent.decide(state, 𝛆)\n","    reward = game.play(p1_action, p2_action)\n","\n","    # Actualizamos el agente\n","    agent.update(Transition(\n","        prev_state=state,\n","        next_state=state,\n","        action=p1_action,\n","        reward=reward\n","    ))\n","\n","    # Actualizamos 𝜀\n","    𝜀 -= 𝛿𝜀 if 𝜀 > 0 else 0"],"metadata":{"id":"uTbSQlKjfInw","executionInfo":{"status":"ok","timestamp":1685376464321,"user_tz":-120,"elapsed":624,"user":{"displayName":"Nacho","userId":"01555914631003755754"}}},"execution_count":82,"outputs":[]},{"cell_type":"markdown","source":["# Resultados del entrenamiento"],"metadata":{"id":"T6g6Zot3gkLf"}},{"cell_type":"code","source":["print(agent.q_table)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fcBf01OzfZ9K","executionInfo":{"status":"ok","timestamp":1685376465766,"user_tz":-120,"elapsed":290,"user":{"displayName":"Nacho","userId":"01555914631003755754"}},"outputId":"c7c903fc-dd45-4159-a99f-d55504ecb2ef"},"execution_count":83,"outputs":[{"output_type":"stream","name":"stdout","text":["{0: {<Action.ROCK: '🪨 Rock'>: 3.6283617857855823, <Action.PAPER: '🧻 Paper'>: 3.6040215510640126, <Action.SCISSORS: '✂️ Scissors'>: 3.639882834789625, <Action.LIZARD: '🦎 Lizard'>: 3.451654015970638, <Action.SPOCK: '🖖 Spock'>: 3.969101960343152}}\n"]}]},{"cell_type":"markdown","source":["# Definicion de los otros agentes para competición"],"metadata":{"id":"9_O1mQtMfkbI"}},{"cell_type":"code","source":["class Botnifacio(Agent):\n","    def __init__(self):\n","        super().__init__(name='Botnifacio')\n","    \n","    def decide(self, state:int) -> Action:\n","        return np.random.choice(list(Action))\n","\n","\n","class Gustabot(Agent):\n","    def __init__(self):\n","        super().__init__(name='Gustabot')\n","        self.weights = np.random.random(5)\n","        self.weights /= sum(self.weights)\n","    \n","    def decide(self, state:int) -> Action:\n","        return np.random.choice(list(Action), p=self.weights)\n","    \n","    def update(self, transition: Transition):\n","        self.weights = np.random.random(5)\n","        self.weights /= sum(self.weights)"],"metadata":{"id":"2v-2U1VSfo9o","executionInfo":{"status":"ok","timestamp":1685376466000,"user_tz":-120,"elapsed":2,"user":{"displayName":"Nacho","userId":"01555914631003755754"}}},"execution_count":84,"outputs":[]},{"cell_type":"markdown","source":["# **Competición**"],"metadata":{"id":"4W9y54MQfzYA"}},{"cell_type":"code","source":["import itertools\n","\n","FRIENDLY_SETS = 10000\n","COMPETITION_SETS = 1000\n","\n","\n","\n","competitors = [\n","     Botnifacio,\n","     Gustabot,\n","     TechNoirAgent,\n","]\n","\n","\n","leaderboard = {c: 0 for c in sorted(competitors, key=lambda x:\n","x().__str__())}\n","game = Game()\n","for p1, p2 in itertools.combinations(leaderboard.keys(), 2):\n","    p1, p2 = p1(), p2()\n","    # Amistoso\n","    s = 0\n","    for i in range(FRIENDLY_SETS):\n","        a1 = p1.decide(s)\n","        a2 = p2.decide(s)\n","        reward = game.play(a1, a2)\n","        p1.update(Transition(prev_state=s, next_state=s, action=a1, reward=reward))\n","        p2.update(Transition(prev_state=s, next_state=s, action=a2, reward=-reward))\n","\n","     # Competición\n","    s = 0\n","    r1 = r2 = 0\n","    for i in range(COMPETITION_SETS):\n","        a1 = p1.decide(s)\n","        a2 = p2.decide(s)\n","        reward = game.play(a1, a2)\n","        r1 += reward\n","        r2 -= reward\n","\n","    # Actualización de marcadores globales\n","    if r1 > r2:\n","        leaderboard[p1.__class__] += 3\n","    elif r2 > r1:\n","        leaderboard[p2.__class__] += 3\n","    else:\n","        leaderboard[p1.__class__] += 1\n","        leaderboard[p2.__class__] += 1\n","\n","    print(f'{p1}: {r1}, {p2}: {r2}')\n","\n","\n","print('LEADERBOARD')\n","for c, r in sorted([(i(), v) for i, v in leaderboard.items()],\n","key=lambda t: t[1], reverse=True):\n","     print(f'{r:<10}\\t{c}')"],"metadata":{"id":"1efKVqJxf19g","executionInfo":{"status":"ok","timestamp":1685376517493,"user_tz":-120,"elapsed":3013,"user":{"displayName":"Nacho","userId":"01555914631003755754"}},"outputId":"f4875b8c-3f6c-4b60-b625-b92422dbbac1","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":94,"outputs":[{"output_type":"stream","name":"stdout","text":["Botnifacio: 15, Gustabot: -15\n","Botnifacio: 9, TechNoir Agent: -9\n","Gustabot: 546, TechNoir Agent: -546\n","LEADERBOARD\n","6         \tBotnifacio\n","3         \tGustabot\n","0         \tTechNoir Agent\n"]}]}]}